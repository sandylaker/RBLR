{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rblr import IFB, ClassicalBootstrap, Preprocessor, \\\n",
    "    StratifiedBootstrap, ModifiedStraitifiedBootstrap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Load and clean dataset\n",
    "### 1.1 load dataset\n",
    "The dataset is the breast cancer dataset from \n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29 It contains 569 observations and each \n",
    "observation has 32 features. There are two types of labels. \"B\" stands for benign, \"M\" stands for malignant. \n",
    "31 out of 32 features consist of numeric values, while the last feature contains a large number of nan values, and the \n",
    "first feature is the ID number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../test_dataset/breast_cancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 clean data and encode labels into numeric values\n",
    "Drop the two redundant columns. Encode \"B\" into 0 and \"M\" into 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove redundant columns\n",
    "df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)\n",
    "# encode diagnosis\n",
    "df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3 prepare data for train and test\n",
    "* extract X and y\n",
    "* min-max normalize each feature of X according to $$x^{'} = \\frac{x - min(x)}{max(x) - min(x)}$$\n",
    "so that values of each feature are located in range from 0 to 1.\n",
    "* split the dataset into train and test datasets, where 0.2 proportion of the dataset will be used as test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X = df.drop(['diagnosis'], axis=1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "# min-max scale\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.4 define a contaminating function to generate outliers\n",
    "Given a fraction  $\\lambda = N_o/N_{train} $\n",
    " (default 0.2), representing the fraction of outliers in clean training dataset, and a factor  $f$\n",
    "  representing the fraction of outliers that will be labelled with 1, that is, the outliers lying on the the same side \n",
    "  as the majority of class 0. The outliers are generated as follows:\n",
    "1. calculate number of outliers : $ N_o = N_{train}\\cdot \\lambda $\n",
    " , and number of outliers that will be labelled with 1:  $N^{(0)}_o= N_o\\cdot f$\n",
    " , and the number of outliers that will be labelled with 0:  $N^{(1)}_o = N_o − N^{(0)}_o$\n",
    " .\n",
    " \n",
    "2. Split the training data into two classes accoring to the label, and randomly sample from each class  $N^{(0)}_o$,\n",
    "$N^{(1)}_o$ number of outliers respectively. We obtain two sampled datasets  $X^{(0)}_s$, $X^{(1)}_s$.\n",
    "3. for each observation $\\mathbf{x}$ in the sampled datasets, generate an oulier as follows, take an example of class 0:\n",
    "$$\\mathbf{x}_o= t_{scale}\\cdot \\mathbf{x} + \\mathbf{x}_{noise}$$ where $t_{scale}$ (default 10) is a magnifer factor \n",
    "and $\\mathbf{x}_{noise}$ is the gaussian noise. Then, reverse the label, i.e. label the outlier with 1.\n",
    "4. concatenate the  $\\mathbf{X}$ and label matrix with training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define a contamination function\n",
    "def contaminate(X_train, y_train, contamination=0.2, scale=10, label_percentage=0.5):\n",
    "    if ((np.max(X_train, axis=0) - np.min(X_train, axis=0)) >1.1).any():\n",
    "        print(np.max(X_train, axis=0) - np.min(X_train, axis=0))\n",
    "        raise ValueError(\"the input matrix is not min-max scaled\")\n",
    "    if label_percentage < 0 or label_percentage >1:\n",
    "        raise ValueError(\"label percentage can only be between 0 and 1\")\n",
    "    np.random.seed()\n",
    "    n_out = int(X_train.shape[0] * contamination)\n",
    "    n_out_0 = int(n_out * label_percentage)\n",
    "    n_out_1 = n_out - n_out_0\n",
    "    \n",
    "    # generate outliers\n",
    "    X_cat_0 = X_train[y_train==0]\n",
    "    X_out_0 = scale * X_cat_0[np.random.choice(X_cat_0.shape[0], n_out_0)] + \\\n",
    "              0.1 * scale * np.random.randn(n_out_0, X_cat_0.shape[1])\n",
    "    # reverse label of 0-class into 1\n",
    "    y_out_0 = np.ones(n_out_0, dtype=int)\n",
    "    \n",
    "    X_cat_1 = X_train[y_train==1]\n",
    "    X_out_1 = scale * X_cat_1[np.random.choice(X_cat_1.shape[0], n_out_1)] + \\\n",
    "              0.1 * scale * np.random.rand(n_out_1, X_cat_1.shape[1])\n",
    "    # reverse label of 1-class into 0\n",
    "    y_out_1 = np.zeros(n_out_1, dtype=int)\n",
    "    \n",
    "    # concatenate X and y\n",
    "    X_train = np.concatenate((X_train, X_out_0, X_out_1), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_out_0, y_out_1), axis=0)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "contamination = 0.3\n",
    "scale = 1\n",
    "X_train_conta, y_train_conta = contaminate(X_train, y_train, contamination, scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Classification with various models and methods\n",
    "Use different models and methods to fit the clean and contaminated data with contamination factor 0.3 respectively, \n",
    "then predict the test dataset and evaluate the accuracies of the models.\n",
    "### 2.1 Classical Logisitc regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical LR on clean data, accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# classical LR on clean data\n",
    "classical_lr = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "classical_lr.fit(X_train, y_train)\n",
    "print('classical LR on clean data, accuracy: %.2f' % (classical_lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical LR on 0.30 contaminated data, accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# classical LR on contaminated data\n",
    "classical_lr.fit(X_train_conta, y_train_conta)\n",
    "print(\"classical LR on %.2f contaminated data, accuracy: %.2f\" \n",
    "      %(contamination, classical_lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Classical Bootstrap\n",
    "# classical bootstrap on clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical Bootstrap on clean data, accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "classical_boot = ClassicalBootstrap(max_iter=500)\n",
    "classical_boot.fit(X_train, y_train)\n",
    "print('classical Bootstrap on clean data, accuracy: %.2f' % (classical_boot.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical bootstrap on 0.30 contaminated data, accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# classical bootstrap on contaminated data\n",
    "classical_boot.fit(X_train_conta, y_train_conta)\n",
    "print('classical bootstrap on %.2f contaminated data, accuracy: %.2f' \n",
    "      %(contamination, classical_boot.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3 Classical Influence Function Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical IFB on clean data, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# classical IFB method on clean data\n",
    "ifb = IFB(fit_intercept=True)\n",
    "ifb.fit(X_train, y_train, quantile_factor=0.9, max_iter=500)\n",
    "print('classical IFB on clean data, accuracy: %.2f' %(ifb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical IFB on 0.30 contaminated data, accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# classical IFB method on contaminated data\n",
    "ifb.fit(X_train_conta, y_train_conta, quantile_factor=0.9, max_iter=500)\n",
    "print('classical IFB on %.2f contaminated data, accuracy: %.2f' \n",
    "      %(contamination, ifb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.4 Preprocessed Influence Function Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed IFB on clean data, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# preprocessed IFB on clean data\n",
    "preprocessor = Preprocessor()\n",
    "X_train_prep , y_train_prep = preprocessor.fit_transform(X_train, y_train)\n",
    "ifb.fit(X_train_prep, y_train_prep)\n",
    "print(\"preprocessed IFB on clean data, accuracy: %.2f\" %(ifb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed IFB on 0.30 contaminated data, accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "# preprocessed IFB on contaminated data\n",
    "preprocessor = Preprocessor()\n",
    "X_train_conta_prep, y_train_conta_prep = preprocessor.fit_transform(X_train_conta, y_train_conta)\n",
    "ifb.fit(X_train_conta_prep, y_train_conta_prep)\n",
    "print('preprocessed IFB on %.2f contaminated data, accuracy: %.2f' \n",
    "      %(contamination, ifb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.5 Stratified Bootstrap\n",
    "* Number of strata: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratified bootstrap on clean data, accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# stratified bootstrap on clean data\n",
    "stratified_boot = StratifiedBootstrap()\n",
    "stratified_boot.fit(X_train, y_train, n_strata=5, metric='residual')\n",
    "print('stratified bootstrap on clean data, accuracy: %.2f'\n",
    "      % (stratified_boot.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Number of bootstrap samples: 10\n",
    "* Number of strata: 5\n",
    "* **Note**: here 10 parallelisms are used. The time effectiveness is somehow unstable, depending on the dataset and bootstrap \n",
    "samples. In good cases the perfomance can reach 147 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----fit bootstrap sample No.0-----\n",
      "-----fit bootstrap sample No.1-----\n",
      "-----fit bootstrap sample No.2-----\n",
      "-----fit bootstrap sample No.3-----\n",
      "-----fit bootstrap sample No.4-----\n",
      "L-BFGS failed to converge: 0 / 5 times\n",
      "stratified boostrap on 0.30 contaminated data, accuracy: 0.95\n",
      "consumed time: 219.55 s\n"
     ]
    }
   ],
   "source": [
    "# stratified bootstrap on contaminated data\n",
    "t1 = time.time()\n",
    "stratified_boot = StratifiedBootstrap(warm_start=True)\n",
    "stratified_boot.fit(X_train_conta, y_train_conta,\n",
    "                    n_bootstrap=5, n_strata=3, metric='residual',\n",
    "                    verbose=True, n_jobs=None, )\n",
    "print('stratified boostrap on %.2f contaminated data, accuracy: %.2f'\n",
    "      %(contamination, stratified_boot.score(X_test, y_test)))\n",
    "print(\"consumed time: %.2f s\" % (time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.6 Modified Stratified Bootstrap\n",
    "* Number of bootstrap samples: 20\n",
    "* Number of strata: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified stratified bootstrap on clean data, accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# modified stratified bootstrap on clean data\n",
    "modified_strat_boot = ModifiedStraitifiedBootstrap()\n",
    "modified_strat_boot.fit(X_train, y_train, n_bootstrap=20, n_strata=2)\n",
    "print('modified stratified bootstrap on clean data, accuracy: %.2f'\n",
    "      %(modified_strat_boot.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "On contaminated data:\n",
    "* Number of bootstrap samples: 20\n",
    "* Number of strata: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified stratified bootstrap on 0.30 contaminated data, accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# modified stratified bootstrap on contaminated data\n",
    "modified_strat_boot = ModifiedStraitifiedBootstrap(max_iter=500)\n",
    "modified_strat_boot.fit(X_train_conta, y_train_conta, n_bootstrap=20, n_strata=3)\n",
    "print('modified stratified bootstrap on %.2f contaminated data, accuracy: %.2f'\n",
    "      %(contamination, modified_strat_boot.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Summary\n",
    "The simulation results are summarized as follows:\n",
    "\n",
    "|Methods| clean data | 0.3 contamination |\n",
    "|---|:---:|:---:|\n",
    "|Classical LR | 0.96 | 0.63 |\n",
    "|Classical Bootstrap | 0.94 | 0.39 |\n",
    "|Classical IFB | 0.97 | 0.80 |\n",
    "|PreprocessedIFB | 0.97 | 0.97 |\n",
    "|Stratified Bootstrap | 0.92 | 0.94 |\n",
    "|Modified Stratified Bootstrap | 0.94 | 0.94 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
